
Nice ðŸ˜„ thatâ€™s the *exact* milestone you want before moving forward.
Now we level up in a **non-flashy but crucial** way.

---

# Phase 2 â€“ Document & text tracking (pygls v2â€“correct)

## Goal (definition of done)

By the end of this phase, your LSP will:

* Track opened documents
* Track incremental text changes
* Know **current file text**
* Know **cursor position**
* Be able to extract **surrounding context**

ðŸ‘‰ Still **no AI**, but now the LSP actually *understands* what the user is editing.

This phase is what separates â€œautocomplete toyâ€ from â€œAI-ready systemâ€.

---

## 1. Architectural intent (why this phase matters)

Autocomplete requests (`textDocument/completion`) do **not** include full document text.

The LSP model is:

* Text is pushed via:

  * `didOpen`
  * `didChange`
* Completion *pulls* context from **your internal state**

So we need:

```
LSP Events â”€â”€â–¶ DocumentStore â”€â”€â–¶ Completion Context
```

---

## 2. Document storage strategy (simple & correct)

Weâ€™ll introduce a **DocumentStore**, responsible for:

* Holding full document text
* Updating on changes
* Exposing read-only helpers

### Design rules

* One responsibility
* No LSP types leaking outside
* Easy to swap later (tree-sitter, rope, etc.)

---

## 3. Implement `documents.py`

```python
# ai_lsp/lsp/documents.py

from dataclasses import dataclass
from typing import Dict
from lsprotocol import types


@dataclass
class Document:
    uri: str
    language_id: str
    version: int
    text: str


class DocumentStore:
    def __init__(self):
        self._documents: Dict[str, Document] = {}

    def open(self, params: types.DidOpenTextDocumentParams) -> None:
        doc = params.text_document
        self._documents[doc.uri] = Document(
            uri=doc.uri,
            language_id=doc.language_id,
            version=doc.version,
            text=doc.text,
        )

    def update(self, params: types.DidChangeTextDocumentParams) -> None:
        uri = params.text_document.uri
        document = self._documents.get(uri)

        if not document:
            return

        # Phase 2: assume full text sync
        for change in params.content_changes:
            document.text = change.text

        document.version = params.text_document.version

    def get(self, uri: str) -> Document | None:
        return self._documents.get(uri)
```

### Important (intentional simplification)

* We assume **full document sync**
* This matches Neovimâ€™s default behavior
* Incremental ranges come later *if needed*

---

## 4. Register document lifecycle handlers

Now we wire this into pygls.

### Update `capabilities.py`

```python
# ai_lsp/lsp/capabilities.py

from pygls.lsp.server import LanguageServer
from pygls.lsp.types import (
    CompletionList,
    CompletionItem,
    CompletionItemKind,
    CompletionOptions,
)
from lsprotocol import types

from ai_lsp.lsp.documents import DocumentStore


def register_capabilities(server: LanguageServer):
    documents = DocumentStore()

    register_documents(server, documents)
    register_completion(server, documents)


def register_documents(server: LanguageServer, documents: DocumentStore):

    @server.feature(types.TEXT_DOCUMENT_DID_OPEN)
    def did_open(ls: LanguageServer, params: types.DidOpenTextDocumentParams):
        documents.open(params)

    @server.feature(types.TEXT_DOCUMENT_DID_CHANGE)
    def did_change(ls: LanguageServer, params: types.DidChangeTextDocumentParams):
        documents.update(params)
```

Now your server is **stateful**.

---

## 5. Use document context in completion

Letâ€™s minimally *prove* it works.

### Update completion handler

```python
def register_completion(server: LanguageServer, documents: DocumentStore):

    @server.feature(
        types.TEXT_DOCUMENT_COMPLETION,
        CompletionOptions(trigger_characters=[".", ":"], resolve_provider=False),
    )
    def on_completion(ls: LanguageServer, params: types.CompletionParams):
        uri = params.text_document.uri
        position = params.position

        document = documents.get(uri)
        if not document:
            return CompletionList(is_incomplete=False, items=[])

        # Extract current line
        lines = document.text.splitlines()
        line = lines[position.line] if position.line < len(lines) else ""

        items = [
            CompletionItem(
                label="hello_world",
                kind=CompletionItemKind.Text,
                detail=f"Line: {line.strip()}",
            ),
            CompletionItem(
                label="hello_ai",
                kind=CompletionItemKind.Text,
                detail=f"Lang: {document.language_id}",
            ),
        ]

        return CompletionList(is_incomplete=False, items=items)
```

---

## 6. Smoke test (important)

Open a file, type:

```python
user.
```

Trigger completion.

You should now see:

* Completion items
* With `detail` reflecting:

  * current line text
  * language ID

If yes â†’ **document tracking works** âœ…

---

## 7. What we have now (this is big)

At this point, your LSP knows:

* âœ” Which file is open
* âœ” Its full content
* âœ” Cursor position
* âœ” Language
* âœ” When text changes

This is **everything an AI needs** to reason.

---

## 8. What we *still* are not doing (on purpose)

* âŒ Symbol extraction
* âŒ AST parsing
* âŒ Project-wide context
* âŒ LLM calls
* âŒ Agents

Weâ€™re still building the spine.

---

## Next step (strong recommendation)

### ðŸ”¥ Phase 3 â€“ Completion Context Builder

This is where we:

* formalize a `CompletionContext` domain object
* extract:

  * prefix token
  * surrounding lines
  * indentation
  * file path
* **prepare the exact input** an LLM or agent will consume

After Phase 3, plugging Ollama becomes trivial.

Say:

* **â€œLetâ€™s do Phase 3â€**
  or
* **â€œI want to adjust the document model firstâ€**

Weâ€™re right on track ðŸš€
