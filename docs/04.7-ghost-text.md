
Perfect sequencing ğŸ‘
Weâ€™ll do this **honestly and pragmatically**, because â€œstreaming inline completionsâ€ sits right at the edge of what **LSP actually supports** today.

Iâ€™ll be very explicit about:

* what is **standard LSP**
* what is **Neovim-specific**
* what is **possible now**
* what is **not worth fighting**

This will save you days of yak-shaving.

---

# Phase 4.7 â€“ Streaming *inline* (ghost text) completions

## First: an important reality check (1 minute, worth it)

### â— LSP does NOT have true â€œstreaming completionsâ€

There is:

* no official â€œtoken streamâ€ for completions
* no way to push partial text updates mid-request
* no server-initiated completion updates

So **all tools that appear to stream** are actually doing one of these:

1. Client fakes streaming (reveals text progressively)
2. Client polls the server repeatedly
3. Server streams tokens internally, but **returns once**

ğŸ‘‰ We will do **#1 + #3**, which is:

* correct
* fast
* widely used
* future-proof

---

## What â€œinline streamingâ€ will mean in *your* system

From the userâ€™s POV:

* Ghost text appears
* It grows smoothly
* Typing cancels it
* `<Tab>` accepts it

From the LSP POV:

* One async request
* One response
* The response contains the **full completion**
* Client reveals it progressively

This is exactly how Copilot works internally.

---

## 1. Neovim responsibility vs LSP responsibility

### LSP server (your code)

* returns **inline-friendly text**
* marks it as **incomplete**
* responds quickly
* cancels aggressively

### Neovim client

* displays ghost text
* animates reveal
* handles accept / reject

ğŸ‘‰ **Streaming UX is a client problem**
ğŸ‘‰ **Reasoning & generation is a server problem**

---

## 2. Use the *right* LSP fields for inline completions

For inline / ghost text, you must use:

```python
CompletionItem(
    insert_text=...,
    insert_text_format=InsertTextFormat.PlainText,
    text_edit=TextEdit(...),
)
```

Why?

* Inline completions must **replace from cursor onward**
* Not insert arbitrarily

---

## 3. Compute a proper `TextEdit`

This is critical.

### Add this helper (LSP-side)

```python
from lsprotocol import types

def make_inline_edit(context, completion_text):
    start = types.Position(
        line=context_cursor.line,
        character=len(context.prefix),
    )
    end = types.Position(
        line=context_cursor.line,
        character=len(context.current_line),
    )

    return types.TextEdit(
        range=types.Range(start=start, end=end),
        new_text=completion_text,
    )
```

But we need cursor position â€” so letâ€™s formalize it.

---

## 4. Extend `CompletionContext` (small but important)

Update your domain model:

```python
# ai_lsp/domain/completion.py

@dataclass(frozen=True)
class CompletionContext:
    language: str
    file_path: str
    prefix: str
    current_line: str
    previous_lines: List[str]
    next_lines: List[str]
    indentation: str
    line: int
    character: int
```

Update the builder accordingly:

```python
return CompletionContext(
    language=document.language_id,
    file_path=...,
    prefix=prefix,
    current_line=full_line,
    previous_lines=previous_lines,
    next_lines=next_lines,
    indentation=indentation,
    line=position.line,
    character=position.character,
)
```

This keeps **domain-level cursor knowledge**, which agents will need later.

---

## 5. Ollama streaming (internal only)

Now we actually *stream* tokens from Ollama â€” but donâ€™t expose them yet.

### Update Ollama call

```python
"stream": True
```

And process the chunks:

```python
def _blocking_complete(self, context):
    response = requests.post(
        f"{self.base_url}/api/generate",
        json={ ... , "stream": True },
        stream=True,
        timeout=self.timeout,
    )

    text = ""
    for line in response.iter_lines():
        if not line:
            continue
        data = json.loads(line)
        if "response" in data:
            text += data["response"]
    return text.strip()
```

### Why do this now?

* Agents will want token-level control
* You can add **early stopping**
* Cancellation becomes more effective

---

## 6. Inline completion item (server side)

Now update the completion handler:

```python
edit = types.TextEdit(
    range=types.Range(
        start=types.Position(
            line=context.line,
            character=len(context.prefix),
        ),
        end=types.Position(
            line=context.line,
            character=len(context.current_line),
        ),
    ),
    new_text=completion,
)

item = CompletionItem(
    label=completion.splitlines()[0][:80],
    kind=CompletionItemKind.Text,
    text_edit=edit,
    insert_text_format=types.InsertTextFormat.PlainText,
)
```

This tells Neovim:

> â€œThis text *replaces* what comes after the cursor.â€

Perfect for ghost text.

---

## 7. Neovim side â€“ enable inline ghost text

### With `nvim-cmp`

```lua
cmp.setup({
  experimental = {
    ghost_text = true,
  },
})
```

Thatâ€™s it.

Now:

* Completion text appears inline
* Not committed
* Tab accepts it

---

## 8. Cancellation behavior (already works ğŸ‰)

Because you already implemented:

* async handlers
* task cancellation
* prefix guards

Typing will:

* cancel the previous completion
* clear ghost text
* start a new request

This is exactly the desired UX.

---

## 9. What we achieved (important)

You now have:

* âœ” Inline ghost text
* âœ” Async LLM calls
* âœ” Best-effort cancellation
* âœ” Streaming internally
* âœ” Zero protocol hacks

This is **the maximum you should do at LSP level**.

Anything more belongs to the client.

---

## 10. What we deliberately did NOT do

* âŒ true token-by-token UI updates (client job)
* âŒ nonstandard LSP extensions
* âŒ server push hacks
* âŒ editor-specific RPCs

You stayed clean.

---

## Next: Phase 5 â€“ Completion Agents ğŸ”¥

Now we finally let intelligence in.

In Phase 5 weâ€™ll add:

* `CompletionAgent`
* intent detection (â€œis this worth an LLM call?â€)
* context pruning
* guardrails against hallucinations
* multiple candidate ranking

And the best part:
ğŸ‘‰ **we wonâ€™t touch the LSP layer at all**

Say it when ready:

> **â€œLetâ€™s do Phase 5 â€“ Completion Agentsâ€**

Youâ€™ve built something *very* solid so far.
